{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ae73d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant that translates {input_language} to {output_language}. Translate the following sentence: {sentence}\"), \n",
    "        (\"human\", \"{sentence}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(prompt.format(input_language=\"English\", output_language=\"French\", sentence=\"Hello, how are you?\"))\n",
    "\n",
    "model = ChatOllama(model=\"llama3.2\", temperature=0.7)\n",
    "\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "print(chain.invoke({\"input_language\": \"English\", \"output_language\": \"French\", \"sentence\": \"Hello, how are you?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c3051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that can suggest some {product} company names. Please provide the names in a comma-separated format.\"),\n",
    "    (\"human\", \"Suggest some company names for a company that makes {product}.\")\n",
    "])\n",
    "\n",
    "chain = prompt | model | CommaSeparatedListOutputParser()\n",
    "\n",
    "try:\n",
    "    print(chain.invoke({\"product\": \"smartphones\"}))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9b5e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "class CompanyName(BaseModel):\n",
    "    names: list[str] = Field(..., description=\"A list of company names in a comma-separated format.\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that can suggest some {product} company names. Please provide the names in {format_instruction}.\"),\n",
    "    (\"human\", \"Suggest some company names for a company that makes {product}.\")\n",
    "])\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=CompanyName)\n",
    "\n",
    "chain = prompt | model | JsonOutputParser(pydantic_object=CompanyName)\n",
    "\n",
    "try:\n",
    "    print(chain.invoke({\"product\": \"smartphones\", \"format_instruction\": parser.get_format_instructions()}))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e437d77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(page_content=\"Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\")\n",
    "\n",
    "document_2 = Document(page_content=\"So she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her.\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Summarize the following documents: {documents}\")\n",
    "\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "try:\n",
    "    print(chain.invoke({\"documents\": [document_1, document_2]}))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66667fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "loader = WebBaseLoader(\"https://en.wikipedia.org/wiki/LangChain\")\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = splitter.split_documents(documents)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "vector_store = Chroma.from_documents(splits, embeddings)\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "def format_documents(documents: list[Document]) -> str:\n",
    "    return \"\\n\\n\".join([document.page_content for document in documents])\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Answer based ONLY on context: {context}\\nQuestion: {question}\")\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "    \"context\": lambda x: format_documents(retriever.invoke(x[\"question\"])),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "    } \n",
    "    | prompt \n",
    "    | model \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(rag_chain.invoke({\"question\": \"What is LangChain?\"}))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092eaf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "\n",
    "loader = WebBaseLoader(\"https://en.wikipedia.org/wiki/LangChain\")\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = splitter.split_documents(documents)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "vector_store = Chroma.from_documents(splits, embeddings)\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "def format_documents(documents: list[Document]) -> str:\n",
    "    return \"\\n\\n\".join([document.page_content for document in documents])\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that answers questions based on the provided {context}.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "    \"context\": lambda x: format_documents(retriever.invoke(x[\"question\"])),\n",
    "    \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "    \"question\": lambda x: x[\"question\"], \n",
    "    } \n",
    "    | prompt \n",
    "    | model \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        _input = input(\"Ask a question (or 'exit' to quit): \")\n",
    "        if _input.lower() == \"exit\":\n",
    "            break\n",
    "        print(f\"You: {_input}\\n\")\n",
    "        response = rag_chain.invoke({\n",
    "            \"question\": _input,\n",
    "            \"chat_history\": chat_history\n",
    "        })\n",
    "        \n",
    "        chat_history.append(HumanMessage(content=_input))\n",
    "        chat_history.append(AIMessage(content=response))\n",
    "\n",
    "        print(f\"AI: {response}\\n\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aee33d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
